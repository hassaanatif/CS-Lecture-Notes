
                                 =============================================================
                                 Lecture 4: Scanning: Finite Automata and Regular Expressions    (JUST INTRODUCTION)                        
                                 ============================================================

=============================
How do compilers do scanning?
=============================
They do it through finite automata and regular expressions. Regular expressions, grammar and automatas are  the tools for recognizing languages. It is also
important to realize that a programming language is a UNION of a bunch of other languages. For example: 

X12 = 32 ; 
--  - -- -
We have tokenized it as the language of all the valid identifiers (i), an assignment operator language (ii), a language consisting of an unsigned constant 
(iii) and an end of statement symbol (iv). So as we can see 4 different languages.
So the union of all these languages will give us a valid program (or a valid string).

================================
From scanning point of view only
=================================
From scanning point of view, a valid program is a program that consists of a sequence of valid tokens. And each token belongs to a valid part of speech 
(for example a valid identifier).


===============
Some old terms
===============
Alphabet: Finite set of symbols
String:  Sequence of symbols from a given alphabet 
Language:  set of strings 
Formal language: To distinguish it from human/natural and programming languages. There is a relation between programming language and a formal
                 language. Language doesn't have to be meaningful or interesting.  Now in this course, we will be defining some languages that 
                 are useful.  

- In a DFA, we have to have a transition for every symbol in the alphabet set.

============================
What does Finite Automata do
============================
It checks for the validity of a string. We can identify REGULAR LANGUAGES with the help of finite automatas and regular expressions. WE can also
use regular grammar to recognize regular languages. 


======================================================
What can you do in an NFA that you cannot do in a DFA
=======================================================
- The empty transition
- More than one transition for a symbol in the alphabet set.
- No transition for some of the symbols in the alphabet set.

==================================
Which one is easier to work with?
==================================
- An NFA.
- Also, every DFA is an NFA. But the opposite is not true.
- There are dead paths in NFA. 
- The NFA is a compact way of representing multiple paths in a more compact way. Usually NFA is more compact than a DFA. It is more comapct because it is 
  encoding multiple paths and multiple possibilities.
- NFA has a large number of paths encoded in it. NFA is a compact way of encoding a large number of paths.
- While an NFA is easier to write, it is very HARD to trace because it is non-deterministic.


=========================================
Which automata is more easier to program
=========================================
- A DFA. Because a DFA is almost ready for programming. It's just a table (transition table) that tells you where  to go. So all that you need to program
  it is a switch statement.
- While NFAs are easier to write, we can more easily represent rules using regular expressions. So a regular expression is much easier to express a general
  rule than an NFA.

==========================================
What can you have in a regular expression
==========================================
- If our Sigma is equal to {0, 1} and we have a regular expression: (0+1)*111(0+1)* then we can write it shorthandedly as (Sigma)*111(Sigma)*  because 
  sigma closure is the union of all possible symbols and zero union 1 is sigma.


========================================
Coverting Regular Expressions into NFAs (Thompson's Construction)
========================================
- Because a regular expression has epsilons in it then that means that it can be easily converted into an NFA. 
- We use Thompson construction to convert a regular expression into an NFA.


=================================================================
So how does this fit into the context of scanners and compilers
=================================================================
So in-fact what happens in scanning...scanners and compilers are built by writing regular expressions for the different parts or for the valid tokens in 
a language like identifiers, floating points, if-statements, whatever. Every valid token...there is a rule that defines it using regular expression. Then 
we take this regular expression that we build for the low level syntax of the langauge (or the micro-syntax)...you know the syntax at the word level. Then
we convert that regular expression into an NFA and then we take that NFA and convert it into a DFA. 
SO we start with a regular expression because a regular expression is the easiest way for humans to DEFINE A RULE for a regular language. But we end up
with a DFA why?? Because we can code it easily!! Trying to write a program that implement a regular expresison means first converting it into an NFA and 
then converting it into a DFA and then programming it. 


===========================================
A tool that will generate a scanner for us
===========================================
What we feed into this tool is a file that has a regular expression in it and the tool converts the regular expression into an NFA and then that NFA into
a DFA. So that conversion is done automatically by the tool that we will be using. It gives you the C-Code. It's called "Flex".
