
                            ============================================================
                            Compilers Lecture 10: Scanning (7): Implementation, Part I
                            ============================================================
===============================
Tools that we are going to use
===============================
We will write a file that has regular expressions in it. And that file will have rules for different syntactic categories in the language. So you will have
RE for integers, RE for identifiers, RE for floats.
The REs are for the words or the syntactic categories for the language. So we will be taking these words and building up sentences from them in the 
parsing stage. Then there will be REs for different keywords. For example: if (which is a trivial RE), RE for for, RE for while. The RE for a keyword is the 
keyword itself because it is a language that has a single string in it which is that keyword. 
Then the union of all the above REs will be a big RE which will be our programming language. 

=================================================
Scanner generator and its internal implementation
=================================================
We have a scanner generator which takes REs and gives us C code for the scanner (which is also known as the scanner code). And internally it does that by 
converting this RE into an NFA using the THOMPSON algorithm. Then it does the SUBSET construction and it converts it into a DFA. Then it minimizes the DFA.
There are algos for minimizing the states of a DFA. DFA minimization algo gives you the minimal DFA. And then you finally generator the code for the scanner
or the DFA. The scanner code is going to be one of the many source files that constitute the compiler source code. So it is only going to be one stage of 
the compiler. 

============
Flex tool
============
This is the tool that we will be using to generate scanner code.

==========================================================================
Difference between compiling applications and building the compiler itself
==========================================================================
All of this will be done while building the compiler. It will not be done while we are compiling the applications.

=================================================================================================
EXAMPLE RE: RE for keywords starting with alphabets and ending with alphabets OR numbers OR BOTH
=================================================================================================
(START STATE) [a-z] -> (SELF LOOP) [a-z] [0-9] //for an identifier 
(START STATE) [0-9] -> (SELF LOOP) [a-z] [0-9] //integers with leading zeros allowed
(START STATE) f -> o -> (ACCEPT STATE) r       //for the "for" keyword. Also each keyword can have its own branch of the NFA
(START STATE) n -> e -> (ACCEPT STATE) w       //for the "new" keyword 
...and then you will have separate NFA branches for other syntactic categories like the above. 

================
The ease of NFA
================
The NFA is easier to understand and it is easier for humans because there are fewer states. But the corresponding DFA will have more states. 

===================
Matching X123 = 59
===================
Our scanner will take the first branch. And the "X" itself will lead to an accept state. But it will still keep scanning UNTILLLL it hits a different token
or delimeter that is not part of the regular expression. Or until it gets to a lexeme that doesn't match the branch taken for this REGEX. So we know that 
there is no transition shown explicitly for the "=" lexeme, so it will lead to a TRAP state or a DEAD state. 
So the scanner will have to ROLLBACK to the last accept and in this case the last accept was X123. So the scanner will identify this lexeme as an identifier.
Next up the "=" will be identified trivially by another branch of the NFA which will lead to an "assignment" syntactic category. 
Next when it gets to the 5, it will then roll back and identify "=" as a valid word. 

=================
End of statement
=================
So this is the process that it will follow and it will stop when it gets to the ";". It recognizess a semicolon as an end of statement. 

==================
The longest match 
==================
In order for the scanner to work, it will have to follow the longest match and not the first match.

=================================
What if we have multiple matches
=================================
What if you have "for"? So if you have "for" then for will match two accept states for an identifier and for a special keyword. Though keep in mind that we
are talking in context of NFA, it will eventually get converted into a CORRESPONDING DFA. So what will we happen if we have multiple matches? Well we 
SPECIFIY PRIORITIES.

=====================
Specifying prorities
=====================
Well this is something that the scanner generator will allow you to do. You can specify priorities. In the FLEX scanner generator, in the file for the RE, 
the priority is based on the order of the regular expression file. So if you specified a Regular expression for a keyword before you specified a RE for an
identifier then in case of multiple matches, it will always recognize the lexeme as a KEYWORD.

===========================================
An altnerative solution for identification
===========================================
Instead of having separate branches for special keywords and identifiers, we can identify everything as "Identifiers" first and then WE CAN CHECK
to see if that identifier matches a keyword or not. You have to check every identifier in a table called a "KEYWORD TABLE" and that table will
have all the keywords in it (if, else, new, for, while etc). So whenever you match an identifier, you check it in the table. If the identifier
is present in the keyword table then it is a keyword otherwise it is a REGULAR IDENTIFIER. 

=======================
Efficient Keyword table
========================
In order to make the keyword table efficient, we should be implementing it as a HASH TABLE because it is the perfect data structure for implementing
this keyword. In fact you can easily do PERFECT HASHING EASILY HERE. But why? Because you know EXACTLY the number of enteries in the table and 
there aren't many enteries in the table. So if you have 50 keywords then 50 enteries will all you have in this table. And if you can do perfect
hashing because the number of enteries is limited, this means that searching for the lexeme that you have matched in CONSTANT or O(1) time
SEARCH.

========================================================================================
Tradeoffs of separate REs or BRANCHES in an NFA as opposed to the KEYWORD TABLE approach
=========================================================================================
- Space disadvantage when implementing as separate REs because when the NFA will get converted into the corresponding DFA then it will have a 
  lot more states in the NFA and in the corresponding DFA as well. The resulting DFA will be much bigger when we have keywords represented as 
  REs.
- In terms of speed, in the hash table implementation, we will have to perform checking. So for every lexeme that matches an identifier we will 
  have to do some checking in the table. And in MOST CASES the result will NOT BE FOUND. WHY? Because in a typical programming language, you have
  more variables names than you have keywords. So most lexemes will be var names or func names. So it is like that for every 100 checks, any 5 
  will be hit the keyword table. So this checking is an OVERHEAD. Even though it is O(1) but it still takes time. It is not zero time. And this
  checking will be done when we are actually compiling the applications. So this is something that will affect the compile speed. It will be done
  when we are actually compiling a million line program. So there is an overhead here. Although it is not too bad because of O(1) but there is 
  still some overhead here. 

============================
Writing the scanner by hand
============================
The scanner is easy enough to be written by hand unlike the parser. Parsing is much more complicated than scanning. So if you have to build a 
scanner by hand, it is not that bad. It is non-trivial ofcourse  but is much easier than building a parser.


========================================================
About the next lecture: Code generation for the scanner
========================================================
We will discuss how the scanner is getting generated. Given a DFA, how will generate a code for that DFA. There will be two approaches:
i) Table driven approach (2D Array)
ii) Directed-Coded approach

Always remember that a DFA can be viewed as a 2D array in which the rows are the states and the columns are the symbols of the alphabets. For
example:
  s0  a  b  c....0  1  2
  s1  .  .  . ... . . . 
  s2
  s3


