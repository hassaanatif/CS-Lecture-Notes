

                            ============================================================
                            Compilers Lecture 11: Scanning (8): Implementation, Part II
                            ============================================================


============================
The "Done by hand" approach
============================
This pertains to code generation for DFA simulation. This code can be written manually or it can be done by hand. You can do the whole scanning process by 
hand. Some compilers use this approach. This means that it is manually coded. And other compilers use a scannner genertors to do this. A scanner generator
like Lex or Flex is fed regular expressions and it gives you the scanner code. 


===========================
Two schemes of generating code
============================
i) Table driven approach
ii) Direct coded approach

===========================
 Table driven approach
============================
Here, a DFA will be a 2D table or a 2D array.  Where the rows are your states (s0, s1,..sN). And the columns are your symbols (0, 1, 2...9, a,b,..z, =, ;..).

=================
The code will be based on table
=================
Based on the current state and also based on the current character that we are reading, we look it up in the table and then we move to the next state. And in
these states, there will be a state that represents an error, the state "Se". 

=============================
The explicit error state "Se"
=============================
What an error state in the NFA corresponds to is a "no transition". In a DFA, you must have an EXPLICIT error state. In NFA, this state is implicit. We need
this state because we need to check if the string that we are scanning stops matching. 

 FOR EXAMPLE: match the following: 
                                  xyz12 = abc;

In the above example, we will match until we hit the "=" character. Hence we will identify it as a lexeme.

============================
Labeling every accept state
============================
For every accept state, you need to label it as that corresponding syntactic category. For example the syntactic category in the above example is an 
identifier. 

======================================
Backtracking to the last accept state
======================================
When you get to the error state, you need to backtrack to the last accept state that you visited. So you then end up taking the longest match. Or the longest
lexeme that matches one of the syntactic categories in this language. This is also known as "roll back". In general, you may want to rollback or backtrack 
a few states back, but most of the times it is going to be just one state back. So that is why in a typical implementation, you put the states in a stack.
So in order to go to the latest accept state, you do the "pop" operation.

===============================
Starting over after recognition
================================
Once you successfully recognize the lexeme and the corresponding syntactic category, you start over. In the above, you start over matching from the "=" 
sign. 

=====================
Stack operation here
=====================
Popping from the stack is also known as "roll back". In general, you may want to rollback or backtrack  a few states back, but most of the times it is 
going to be just one state back. So that is why in a typical implementation, you put the states in a stack. So in order to go to the latest accept state, 
you do the "pop" operation. And you also need to have a mechanism to determine whether a particular state is an ACCEPT state or not. In a typical 
implementation, you may have an object and there could be a label in that particular object that tells whether it is an accept state or not. 

===========================
Resolving multiple matches
===========================
A particular accept state may belong to more than one syntactic categories and one way to resolve this conflict would be to give priorities to the different
syntactic categories. And a simple way of specifying the categories is just to go by the order in which they are listed in the regular expression file. The
file that you are using to generate a scanner for.

===========================
Redundancy in the table
===========================
Where is the redundancy in our table? Something that is taking unncessarily more space than it should? So all the numbers would be treated equally in most 
cases. So if two columns (like a, b etc) most likely will have the same transitions because they are treated equally. So if you multiple columns like these
then you can categorize the symbols of the alphabets by the "letters" category. And then the "digits" categories. Your actual transition table will then
be based on the categories. 

===========================
The categorization table
============================
You will have your categorization table look like this: 
                                                         0   1    2    3    4     a     b
                                                      digit digit .............letter...letter

And then the transition table will look like this: 
                                                      digit   letter   ;   
                                                   s0
                                                   s1
                                                   s2

So essentially there are symbols that you will have their own categories. And then there are multiple symbols that will get mapped to the same category. 
So this will minimize the number of columns.


=======================================
What if leading zeros were not allowed?
========================================
In that case, the above digits will probably be replaced by a non-zero digits category and then the zero will have its own category. And REMEMBER! You can 
put symbols in the same category only if they have identical transitions in all cases, for all states (if the corresponding columns are similar). 


==================================================================
What is the price that we are paying by dividing into two tables? 
==================================================================  
The price that we are paying here is two times table lookups. So although it is space efficient, it is not performance efficient. But sometimes, though, space
CAN AFFECT THE SPEED.

==================================
Space can AFFECT THE SPEED AS WELL
==================================
So using a lot of space can SLOW DOWN YOUR PROGRAM SOMETIMES. WHY?? BECAUSE OF CACHING. Sometimes using a lot of space means that your
data set doesn't fit in the cache which means a lot of slow down. It obviously depends on the size of your cache and whether the WHOLE DATA that your program
is accessing at a given point or phase can fit into the cache. 


================================================
Can we have identical states or identical rows?
================================================
If you don't do DFA minimization then you may have identical rows. DFA minimization is about merging multiple states that have identical transitions on all
symbols into state. You identify them as equivalent states. If you do DFA minimization you will NOT have identical rows but you will have identical columns.


=======================================
Psuedocode-- Adopting two table lookup
=======================================
state = s0 
lexeme = empty  
stack.push(NullState)
stack.clear() //BUT DO NOT GET RID OF THE NULL STATE

while (state != Se) 
  char = GetNextChar()
  lexeme = lexeme + char
  stack.push(state) 
  if (state belongs to set of accept states) 
       Stack.clear() //BUT DO NOT GET RID OF THE NULL STATE, also we're getting rid of everything because we only care about the LATEST ACCEPT STATE WHILE ROLLBACK.
   
  cat = CatTable[char]
  state = TransitionTable[state][cat]


//Exits loop and now we have to roll back. 

  while (state != SetOftheACCEPTStates && state != NULL) 
      state = stack.pop() 
      truncate lexeme //remove last character
      Rollback        //move the pointer in the lexeme to the previous character
  
  if (state BELONGS to SetOfAcceptStates) 
     return Type[state]   //This is assuming that the type table will have a way to resolve the conflict for multiple syntactic categories.
  else 
     return error  //we couldn't match.


============================
What to do about the lexeme
============================
Your lexeme is a string that you are saving in a certain buffer. And to truncate it, you just go back to the previous index in the buffer. How to return the
lexeme? In fact, when you write an actual scanner, it will be saved in a certain variable. So there will be a certain variable that saves the lexeme. So 
there is a return value which is the syntactic category and the lexeme itself will be saved in a certain variable for holding the lexeme. You need both. You
need to know that it is an identifier but knowing that it is an identifier is not enough. You need an actual name as a compiler because the compiler needs
to create a variable with that name.

=====================
Direct coded scanner
=====================
A direct coded scanner is a one that does not use tables. We will not have a loop. We will have an initialization or start code. Then instead of having a 
loop, there will be states. So instead of using the tables, you DIRECTLY CODE THE TRANSITION TO THE NEXT STATE.

==================================
Pseudocode -- DIRECT CODED SCANNER
==================================
Start: 
      state = s0 
      lexeme = empty
      stack.clear() 
      stack.push(NULL) 

S1: 
     char = GetNextChar() 
     lexeme = lexeme + char 
     if (state belongs to set of accept states) 
         stack.clear() 
     
     if (char == 'a')  goto s2
else if (char == ' ') goto s5
else goto End 


End: 
   while (state DOES NOT BELONG TO SET OF ACCEPT STATES && STATE != NULL) 
      state = stack.pop() 
      truncate lexeme 
      Rollback 
    
   if state belongs to Set of Accept States
      return Type [State] 
   else 
      return error 


=============================================
Advantages and disadvantages of Direct Coded
==============================================
This will look ugly (direct coded). It is ugly and messy if this is code that you would write manually. This is not the code that you would write manually 
typically. This is the code that you will get automatically generated by the SCANNER GENERATOR. You feed the regular expressions into the scanner generator
and it will generate it for you. So this is the code THAT YOU WILL NEVER HAVE TO DEBUG. FLEX probably uses a direct coded approach.
Inspite of the disadvantege of this, the big advantage here is the AVOIDANCE OF MEMORY ACCESS. 
Direct coded is only for one language, but with table driven approach, you can use it for almost any language.
From software engineering point of view, this direct coded approach is terrible when written manually by hand but it is automatically generated for us.
  